{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ZN=F': ['ZN', '10-Year T-Note Futures'], 'DX-Y.NYB': ['DXY', 'US Dollar Index'], 'CL=F': ['CL', 'Crude Oil futures'], 'GC=F': ['GC', 'Gold futures'], 'NQ=F': ['NQ', 'Nasdaq 100 futures'], '^DJI': ['DJI', 'Dow Jones Industrial Average'], '^GSPC': ['GSPC', 'S&P 500']}\n"
     ]
    }
   ],
   "source": [
    "### Step 1: Import Required Libraries\n",
    "import datetime\n",
    "from datetime import date, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import os\n",
    "import shutil #deleting directories\n",
    "\n",
    "### Step 2: Tickers and corresponding symbols\n",
    "dict_symbols = {\n",
    "    \"ZN=F\":[\"ZN\",\"10-Year T-Note Futures\"],\n",
    "    \"DX-Y.NYB\":[\"DXY\",\"US Dollar Index\"],\n",
    "    \"CL=F\":[\"CL\",\"Crude Oil futures\"],\n",
    "    \"GC=F\":[\"GC\",\"Gold futures\"],\n",
    "    \"NQ=F\":[\"NQ\",\"Nasdaq 100 futures\"],\n",
    "    \"^DJI\":[\"DJI\",\"Dow Jones Industrial Average\"],\n",
    "    \"^GSPC\":[\"GSPC\",\"S&P 500\"]}\n",
    "    # \"FGBL=F\":[\"FGBL\",\"German 10-Year Bund\"]\n",
    "    # \"FOAT=F\":[\"FOAT\",\"French 10-year OAT\"]\n",
    "    # \"G=F\":[\"G\", \"UK 10-Year Gilt\"]\n",
    "print(dict_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 3: Make Folders to Store Data\n",
    "Intraday_data_files = \"Intraday_data_files\"\n",
    "os.makedirs(Intraday_data_files, exist_ok=True)\n",
    "Daily_backup_files=\"Daily_backup_files\"\n",
    "os.makedirs(Daily_backup_files, exist_ok=True)\n",
    "os.makedirs('temp',exist_ok=True)#to create new files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Intraday data (1m interval) from 2024-11-17 to 2024-11-18\n",
      "Date Intervals: [['2024-11-17', '2024-11-18']]\n"
     ]
    }
   ],
   "source": [
    "### Step 4: Make Start-End Date Pairs\n",
    "def make_start_end_pairs(days=29,steps=7):\n",
    "    steps=-1*steps\n",
    "    # Get today's date\n",
    "    today = (datetime.datetime.now())\n",
    "    end_intraday=(today-timedelta(days=1)).strftime(\"%Y-%m-%d\")#doing this to get complete data of previous day\n",
    "    start_intraday = (today - timedelta(days=days)).strftime(\"%Y-%m-%d\")\n",
    "    print(f'Fetching Intraday data (1m interval) from {start_intraday} to {end_intraday}')\n",
    "    # Make List of all possible Start-End dates between today and today-30\n",
    "    alldates=[]\n",
    "    for i in range(days,0,steps):\n",
    "        alldates.append((today-timedelta(days=i)).strftime(\"%Y-%m-%d\"))\n",
    "    grouped_start_last_dates=[[a,b] for a,b in zip(alldates,alldates[1:])]\n",
    "    print('Date Intervals:',grouped_start_last_dates)\n",
    "    return grouped_start_last_dates\n",
    "grouped_start_last_dates=make_start_end_pairs(days=2,steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  7 of 7 completed\n",
      "\n",
      "2 Failed downloads:\n",
      "['^DJI', '^GSPC']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-11-17 -> 2024-11-18)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbols ['ZN', 'DXY', 'CL', 'GC', 'NQ', 'DJI', 'GSPC']\n",
      "Tickers ['ZN=F', 'DX-Y.NYB', 'CL=F', 'GC=F', 'NQ=F', '^DJI', '^GSPC']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qc/knz8bs196t30_fkh2jr17kh80000gn/T/ipykernel_5792/222001534.py:19: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  tickers_as_columns=data.stack(level=0,future_stack=False)\n"
     ]
    }
   ],
   "source": [
    "### Step5: Get data for all tickers for the given start-end date pairs\n",
    "def combine_all_data(list_of_first_last,list_of_symbols): # Append the data for all the Start-End dates\n",
    "    datalist=[]\n",
    "    for data in list_of_first_last:\n",
    "        start=data[0]\n",
    "        end=data[1]\n",
    "        interval='1m'\n",
    "        data = yf.download(list_of_symbols, start=start, end=end, interval=interval) #Returns a dataframe\n",
    "        datalist.append(data)\n",
    "    return (pd.concat(datalist))\n",
    "\n",
    "alltickers=list(dict_symbols.keys())\n",
    "allsymbols=[i[0] for i in list(dict_symbols.values())]\n",
    "print('Symbols',allsymbols)\n",
    "print('Tickers',alltickers)\n",
    "# Fetch Data\n",
    "data = combine_all_data(grouped_start_last_dates,list_of_symbols=alltickers)\n",
    "\n",
    "tickers_as_columns=data.stack(level=0,future_stack=False)\n",
    "tickers_as_columns.index.names=['Datetime','Price']\n",
    "\n",
    "### Step6: Store this data in Daily_backup_files folder\n",
    "for col in tickers_as_columns.columns:\n",
    "   \n",
    "    col_data=tickers_as_columns[col].unstack()\n",
    "    dict_symbols[col].append(col_data)\n",
    "    start_date=grouped_start_last_dates[0][0]\n",
    "    end_date=grouped_start_last_dates[-1][-1]\n",
    "    start_end_date=f'Intraday_{dict_symbols[col][0]}_{start_date}_to_{end_date}.csv'\n",
    "    col_data.to_csv(\n",
    "        os.path.join(Daily_backup_files,start_end_date)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ZN', 'DXY', 'CL', 'GC', 'NQ', 'DJI', 'GSPC']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names=[dict_symbols[key][0] for key in dict_symbols.keys()]\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step7: Merge the newly created files with original files\n",
    "\n",
    "for key in names:\n",
    "    for entry in os.scandir(Daily_backup_files):\n",
    "            if entry.is_file() and entry.name.endswith('.csv'):\n",
    "                [_,ticker,newstart,_,newend]=(entry.name.replace('.csv',\"\")).split('_')\n",
    "                if ticker==key and f'{newstart}_{newend}'==f'{grouped_start_last_dates[0][0]}_{grouped_start_last_dates[-1][-1]}':\n",
    "                    newcsvpath=os.path.join(Daily_backup_files,entry.name)\n",
    "                    newcsv=pd.read_csv(newcsvpath)\n",
    "                    newcsv.reset_index(drop=True,inplace=True)\n",
    "\n",
    "    for entry2 in os.scandir(Intraday_data_files):\n",
    "            if entry2.is_file() and entry2.name.endswith('.csv'):\n",
    "                oldcsvpath=os.path.join(Intraday_data_files,entry2.name)\n",
    "                [_,_,ticker,oldstart,_,oldend]=(entry2.name.replace('.csv',\"\")).split('_')\n",
    "                if ticker==key:\n",
    "                    oldcsvpath=os.path.join(Intraday_data_files,entry2.name)\n",
    "                    oldcsv=pd.read_csv(oldcsvpath)\n",
    "                    oldcsv.reset_index(drop=True,inplace=True)\n",
    "  \n",
    "   \n",
    "    finalcsv=pd.concat( (oldcsv,newcsv),axis=0)\n",
    "    finalcsv.drop_duplicates(inplace=True)\n",
    "    finalcsv.dropna(inplace=True)\n",
    "    finalcsv.reset_index(drop=True,inplace=True)\n",
    "    finalstart=str(finalcsv.iloc[0,0])[:10]\n",
    "    finalend=str(finalcsv.iloc[(finalcsv.shape[0]-1),0])[:10]\n",
    "    start_end=f'{finalstart}_to_{finalend}'\n",
    "    finalpath=os.path.join('temp',f'Intraday_data_{key}_{start_end}.csv')\n",
    "    finalcsv.to_csv(finalpath,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory Intraday_data_files and its contents deleted successfully.\n",
      "Directory renamed from 'temp' to 'Intraday_data_files'\n"
     ]
    }
   ],
   "source": [
    "### Step8: Delete the Intraday_data_files directory and rename temp as that directory\n",
    "\n",
    "#Delete\n",
    "directory_path = Intraday_data_files\n",
    "try:\n",
    "    shutil.rmtree(directory_path)\n",
    "    print(f\"Directory {directory_path} and its contents deleted successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"The directory does not exist.\")\n",
    "except PermissionError:\n",
    "    print(\"You do not have the necessary permissions to delete this directory.\")\n",
    "\n",
    "#Rename\n",
    "current_name = \"temp\"\n",
    "new_name = \"Intraday_data_files\"\n",
    "\n",
    "try:\n",
    "    os.rename(current_name, new_name)\n",
    "    print(f\"Directory renamed from '{current_name}' to '{new_name}'\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Directory '{current_name}' not found!\")\n",
    "except PermissionError:\n",
    "    print(\"You do not have permission to rename this directory.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
